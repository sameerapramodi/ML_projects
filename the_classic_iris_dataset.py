# -*- coding: utf-8 -*-
"""The classic iris dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XoJcmwvdorlHVap1aUIuKdKAttrAaYqO
"""

!which python #find the path of the Python interpreter being used.

import os # Python's built-in library for interacting with the operating system
import pandas as pd #library for data manipulation and analysis
import numpy as np #library for numerical computing in Python
import matplotlib.pyplot as plt #creating visualizations
import seaborn as sns # A data visualization library

sns.set_context()  # Adjusts the font size for presentations

from sklearn import datasets

# Now you can load the iris dataset
data = datasets.load_iris()

print(data["DESCR"])

data["data"][:5]

data["feature_names"]

data["target"]

from sklearn import datasets

# Load the Iris dataset
data = datasets.load_iris()

# Access the target names
print(data["target_names"])

"""we are trying to use attributes of flowers to predict the species of the flower. specifically, the sepal length, width, petal length, width to predict if an Iris flower is of type_setosa, type_versicolor, type_virginica. this is multiclass classification problem.

#create a pandas dataframe from the data
we could do our full analysis using Numpy and Numpy arrays, but we will create a Pandas dataframe beacause it does make something simpler, and also to get some practice using pandas.
"""

df = pd.DataFrame(data["data"], columns=data["feature_names"])

df["target"] = data["target"]

df.head()

"""# Basic descriptive statistics"""

df.describe()

"""#Distribution of features and target"""

col = "sepal length (cm)"
df[col].hist()
plt.title(col)
plt.show()

col = "sepal width (cm)"
df[col].hist()
plt.title(col)
plt.show()

col = "petal length (cm)"
df[col].hist()
plt.title(col)
plt.show()

col = "petal width (cm)"
df[col].hist()
plt.title(col)
plt.show()

"""# Relationship of the data features with the target"""

#create new column with the species name
df["target_name"] = df["target"].map({0: "setosa", 1: "versicolor", 2: "virginica"})

col = "sepal length (cm)"
sns.relplot(x=col, y="target", hue="target_name", data=df)
_=plt.suptitle(col, y=1.05)

col = "sepal width (cm)"
sns.relplot(x=col, y="target", hue="target_name", data=df)
_=plt.suptitle(col, y=1.05)

col = "petal length (cm)"
sns.relplot(x=col, y="target", hue="target_name", data=df)
_=plt.suptitle(col, y=1.05)

col = "petal width (cm)"
sns.relplot(x=col, y="target", hue="target_name", data=df)
_=plt.suptitle(col, y=1.05)

"""#Exploratory Data Analysis (EDA) - Pairplots"""

sns.pairplot(df, hue="target_name")

"""#Train test split
you always want to evaluate your final model on a test set that hasn't been used at all in the training process. so we'll split off a test set here. use cross validation, it is considered as a best practice
"""

from sklearn.model_selection import train_test_split

df_train, df_test = train_test_split(df, test_size=0.25)

df_train.shape

df_test.shape

df_train.head()

"""#Prepare our data for modeling
This involves the data back out into plain NumPy arrays
"""

X_train = df_train[data["feature_names"]].values
y_train = df_train["target"].values

y_train.shape

df_train[data["feature_names"]].head()

"""#Modeling - What is our baseline?
What is the simplest model we can think of?
In this case, if our baseline model is just randomly guessing the species of flower, or guessing a single species for every data point, we would expect to have a model accuracy of 0.33 or 33%, since we have 3 different classes that are evently balanced. So our model should at least 33% accuracy

#Modeling - Simple manual model
Let's manually look at data and decide cutoff points for classification.
"""

data["target_names"]

def single_feature_prediction(petal_length):
    if petal_length < 2:
        return 0
    elif petal_length < 5:
        return 1
    else:
        return 2

df_train.columns

df_train["petal length (cm)"].values

manual_y_predictions = np.array([single_feature_prediction(val) for val in X_train[:,2]])

manual_model_accuracy = np.mean(manual_y_predictions == y_train)

print(f"Our manual model has an accuracy of {manual_model_accuracy*100:.2f}%")

"""#Modeling - Logistic Regression"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()

#Xt stands "x train", and Xv stands for "X validation"
Xt,Xv,yt,yv = train_test_split(X_train, y_train, test_size=0.25)

Xt.shape

Xv.shape

model.fit(Xt, yt)

y_pred = model.predict(Xv)

np.mean(y_pred == yv)

model.score(X_train, y_train)

"""Using cross-validation to evaluate our model"""

from sklearn.model_selection import cross_val_score, cross_val_predict

model = LogisticRegression(max_iter=200)

accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")

np.mean(accuracies)

"""#Where are we misclassifying points?"""

y_pred = cross_val_predict(model, X_train, y_train, cv=5)

predicted_correctly_mask = y_pred == y_train

predicted_correctly_mask

not_predicted_correctly = predicted_correctly_mask

X_train[not_predicted_correctly]

df_predictions = df_train.copy()

df_predictions["correct_prediction"] = predicted_correctly_mask

df_predictions["prediction"] = y_pred

df_predictions["prediction_label"] = df_predictions["prediction"].map({0: "setosa", 1: "versicolor", 2: "virginica"})

df_predictions.head()

sns.scatterplot(x="petal length (cm)", y="petal width (cm)", hue="prediction_label", data=df_predictions)

sns.scatterplot(x="petal length (cm)", y="petal width (cm)", hue="target_name", data=df_predictions)

def plot_incorrect_predictions(df_predictions, x_axis_feature, y_axis_feature):
    fig, axs = plt.subplots(2, 2, figsize(10, 10))
    axs = axs.flatten()
    sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="prediction_label", data=df_predictions, ax=axs[0])

fig, axs = plt.subplots(2, 2, figsize=(10, 10))
axs = axs.flatten()
axs.shape

import matplotlib.pyplot as plt
import seaborn as sns

def plot_incorrect_predictions(df_predictions, x_axis_feature, y_axis_feature):
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    axs = axs.flatten()

    # Plot with 'prediction_label' as hue
    sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="prediction_label", data=df_predictions, ax=axs[0])
    axs[0].set_title('Prediction Label')

    # Plot with 'target_name' as hue
    sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="target_name", data=df_predictions, ax=axs[1])
    axs[1].set_title('Target Name')

    # Plot with 'correct_prediction' as hue
    sns.scatterplot(x=x_axis_feature, y=y_axis_feature, hue="correct_prediction", data=df_predictions, ax=axs[2])
    axs[2].set_title('Correct Prediction')

    axs[3].set_visible(False)

    plt.tight_layout()
    plt.show()

plot_incorrect_predictions(df_predictions, "petal length (cm)", "petal width (cm)")

"""#Model tuning
model tuning is trying to determine the parameters of your model. this is known as hypermeters that maximize the model performance.
"""

LogisticRegression?

model = LogisticRegression(max_iter=200)

for reg_param in (1, 1.3, 1.8, 2, 2.5, 3):
    model.set_params(C=reg_param)
    model = LogisticRegression(max_iter=200, C=reg_param)
    accuracies = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
    print(f"Accuracy for C={reg_param}: {np.mean(accuracies)}")

"""#Final Model"""

model = LogisticRegression(max_iter=200, C=2)

"""#How well does our model do on the Test set"""

X_test = df_test[data["feature_names"]].values
y_test = df_test["target"].values

X_test.shape

y_test.shape

"""Train our final model using our full training dataset"""

# Fit the model with the training data
model.fit(X_train, y_train)

y_test_pred = model.predict(X_test)

test_set_correctly_classified = y_test_pred == y_test
test_set_accuracy = np.mean(y_test_pred == y_test)

print(f"Test set accuracy:{test_set_accuracy * 100:.2f}")

df_predictions_test = df_test.copy()
df_predictions_test["correct_prediction"] = test_set_correctly_classified
df_predictions_test["prediction"] = y_test_pred
df_predictions_test["prediction_label"] = df_predictions_test["prediction"].map({0: "setosa", 1: "versicolor", 2: "virginica"})

df_predictions_test.head()

plot_incorrect_predictions(df_predictions_test, x_axis_feature="petal length (cm)", y_axis_feature="petal width (cm)")

"""#In conclusion
we achieve 95% accuracy on the test dataset using logistic regression model
parameters: LogisticRegression(C=2, max_iter=200)
"""